<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Turi Create: turi::neural_net::model_spec Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Turi Create
   &#160;<span id="projectnumber">4.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('classturi_1_1neural__net_1_1model__spec.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-types">Public Types</a> &#124;
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="classturi_1_1neural__net_1_1model__spec-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">turi::neural_net::model_spec Class Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p><code>#include &lt;<a class="el" href="model__spec_8hpp_source.html">ml/neural_net/model_spec.hpp</a>&gt;</code></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-types"></a>
Public Types</h2></td></tr>
<tr class="memitem:a0d1aa5b0fcc3c11248e0a2e33c49ff4f"><td class="memItemLeft" align="right" valign="top">enum &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a0d1aa5b0fcc3c11248e0a2e33c49ff4f">padding_type</a> </td></tr>
<tr class="separator:a0d1aa5b0fcc3c11248e0a2e33c49ff4f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a972ab38f4986dabfac28beaee2ae01ce"><td class="memItemLeft" align="right" valign="top">enum &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a972ab38f4986dabfac28beaee2ae01ce">padding_policy</a> </td></tr>
<tr class="separator:a972ab38f4986dabfac28beaee2ae01ce"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:af1ff523b7e54fe4869bc6cbee430afaa"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#af1ff523b7e54fe4869bc6cbee430afaa">model_spec</a> ()</td></tr>
<tr class="separator:af1ff523b7e54fe4869bc6cbee430afaa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afe558dd5f6c1480738de3da6e82c0d11"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#afe558dd5f6c1480738de3da6e82c0d11">model_spec</a> (const CoreML::Specification::NeuralNetwork &amp;nn_model)</td></tr>
<tr class="separator:afe558dd5f6c1480738de3da6e82c0d11"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7b0e02b00b3e555b59928311a0318439"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a7b0e02b00b3e555b59928311a0318439">model_spec</a> (const std::string &amp;mlmodel_path)</td></tr>
<tr class="separator:a7b0e02b00b3e555b59928311a0318439"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4d8bdc11e8d0b74a416a9ccfba8cb4c8"><td class="memItemLeft" align="right" valign="top">const CoreML::Specification::NeuralNetwork &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a4d8bdc11e8d0b74a416a9ccfba8cb4c8">get_coreml_spec</a> () const</td></tr>
<tr class="separator:a4d8bdc11e8d0b74a416a9ccfba8cb4c8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abd51b4228a76c35335450b7066f8f86c"><td class="memItemLeft" align="right" valign="top">std::unique_ptr&lt; CoreML::Specification::NeuralNetwork &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#abd51b4228a76c35335450b7066f8f86c">move_coreml_spec</a> () &amp;&amp;</td></tr>
<tr class="separator:abd51b4228a76c35335450b7066f8f86c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a773b3150e362e3e5fb094e75b92baf36"><td class="memItemLeft" align="right" valign="top">float_array_map&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a773b3150e362e3e5fb094e75b92baf36">export_params_view</a> () const</td></tr>
<tr class="separator:a773b3150e362e3e5fb094e75b92baf36"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aec2f3705367eac080429f63f2623166c"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#aec2f3705367eac080429f63f2623166c">update_params</a> (const float_array_map &amp;weights)</td></tr>
<tr class="separator:aec2f3705367eac080429f63f2623166c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:accf5b8ba3d48fdaf91f66a680260a216"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#accf5b8ba3d48fdaf91f66a680260a216">has_layer_output</a> (const std::string &amp;layer_name) const</td></tr>
<tr class="separator:accf5b8ba3d48fdaf91f66a680260a216"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afa970eb6f824e6cf77d4de223594bd3b"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#afa970eb6f824e6cf77d4de223594bd3b">add_relu</a> (const std::string &amp;name, const std::string &amp;input)</td></tr>
<tr class="separator:afa970eb6f824e6cf77d4de223594bd3b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acb6626db8f0340e548cff0bd05ac0ad4"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#acb6626db8f0340e548cff0bd05ac0ad4">add_leakyrelu</a> (const std::string &amp;name, const std::string &amp;input, float alpha)</td></tr>
<tr class="separator:acb6626db8f0340e548cff0bd05ac0ad4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a18df584c6e1eef1cf34fbcb043e935dd"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a18df584c6e1eef1cf34fbcb043e935dd">add_sigmoid</a> (const std::string &amp;name, const std::string &amp;input)</td></tr>
<tr class="separator:a18df584c6e1eef1cf34fbcb043e935dd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aafcbd879d251f3e3ffff3432b25b5df4"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#aafcbd879d251f3e3ffff3432b25b5df4">add_pooling</a> (const std::string &amp;name, const std::string &amp;input, size_t kernel_height, size_t kernel_width, size_t stride_h, size_t stride_w, <a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a0d1aa5b0fcc3c11248e0a2e33c49ff4f">padding_type</a> padding, bool use_poolexcludepadding=false)</td></tr>
<tr class="separator:aafcbd879d251f3e3ffff3432b25b5df4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7ccd214f01f5f7d61ed0a22a090b8751"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a7ccd214f01f5f7d61ed0a22a090b8751">add_convolution</a> (const std::string &amp;name, const std::string &amp;input, size_t num_output_channels, size_t num_kernel_channels, size_t kernel_height, size_t kernel_width, size_t stride_h, size_t stride_w, <a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a0d1aa5b0fcc3c11248e0a2e33c49ff4f">padding_type</a> padding, weight_initializer weight_initializer_fn, weight_initializer bias_initializer_fn=nullptr)</td></tr>
<tr class="separator:a7ccd214f01f5f7d61ed0a22a090b8751"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aea19bc2e165a8934924604187c3e7945"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#aea19bc2e165a8934924604187c3e7945">add_padding</a> (const std::string &amp;name, const std::string &amp;input, size_t padding_top, size_t padding_bottom, size_t padding_left, size_t padding_right, <a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a972ab38f4986dabfac28beaee2ae01ce">padding_policy</a> policy=padding_policy::REFLECTIVE)</td></tr>
<tr class="separator:aea19bc2e165a8934924604187c3e7945"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a54185bc37553c8ea489b2f062e5d58d6"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a54185bc37553c8ea489b2f062e5d58d6">add_upsampling</a> (const std::string &amp;name, const std::string &amp;input, size_t scaling_x, size_t scaling_y)</td></tr>
<tr class="separator:a54185bc37553c8ea489b2f062e5d58d6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5265c68c0395de316c21f0c12ce699e3"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a5265c68c0395de316c21f0c12ce699e3">add_inner_product</a> (const std::string &amp;name, const std::string &amp;input, size_t num_output_channels, size_t num_input_channels, weight_initializer weight_initializer_fn, weight_initializer bias_initializer_fn=nullptr)</td></tr>
<tr class="separator:a5265c68c0395de316c21f0c12ce699e3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a583420894fa2754f703fa1933ba88f11"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a583420894fa2754f703fa1933ba88f11">add_batchnorm</a> (const std::string &amp;name, const std::string &amp;input, size_t num_channels, float epsilon)</td></tr>
<tr class="separator:a583420894fa2754f703fa1933ba88f11"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab27561c305aa88745d19e5ea44294d52"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#ab27561c305aa88745d19e5ea44294d52">add_instancenorm</a> (const std::string &amp;name, const std::string &amp;input, size_t num_channels, float epsilon)</td></tr>
<tr class="separator:ab27561c305aa88745d19e5ea44294d52"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a58b191a4c24d2c4efb49c48ac8eb0ea0"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a58b191a4c24d2c4efb49c48ac8eb0ea0">add_channel_concat</a> (const std::string &amp;name, const std::vector&lt; std::string &gt; &amp;inputs)</td></tr>
<tr class="separator:a58b191a4c24d2c4efb49c48ac8eb0ea0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a903131139a2277c91efae7e68916f13a"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a903131139a2277c91efae7e68916f13a">add_softmax</a> (const std::string &amp;name, const std::string &amp;input)</td></tr>
<tr class="separator:a903131139a2277c91efae7e68916f13a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4a12f8427abded091d6b9bc25758e217"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a4a12f8427abded091d6b9bc25758e217">add_flatten</a> (const std::string &amp;name, const std::string &amp;input)</td></tr>
<tr class="separator:a4a12f8427abded091d6b9bc25758e217"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1e1623161bae417d84204c4e9b965c3b"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a1e1623161bae417d84204c4e9b965c3b">add_addition</a> (const std::string &amp;name, const std::vector&lt; std::string &gt; &amp;inputs)</td></tr>
<tr class="separator:a1e1623161bae417d84204c4e9b965c3b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3a17edc293d3f7bf22cc32ac23183ade"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a3a17edc293d3f7bf22cc32ac23183ade">add_multiplication</a> (const std::string &amp;name, const std::vector&lt; std::string &gt; &amp;inputs)</td></tr>
<tr class="separator:a3a17edc293d3f7bf22cc32ac23183ade"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a87f4589de4b9fa9ae4733a6229dd6c0e"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a87f4589de4b9fa9ae4733a6229dd6c0e">add_exp</a> (const std::string &amp;name, const std::string &amp;input)</td></tr>
<tr class="separator:a87f4589de4b9fa9ae4733a6229dd6c0e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6c69a0731e05e63c9a8f7545381ac730"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a6c69a0731e05e63c9a8f7545381ac730">add_scale</a> (const std::string &amp;name, const std::string &amp;input, const std::vector&lt; size_t &gt; &amp;shape_c_h_w, weight_initializer scale_initializer_fn)</td></tr>
<tr class="separator:a6c69a0731e05e63c9a8f7545381ac730"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4f0880d0964b3c08382d7c018c46824d"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a4f0880d0964b3c08382d7c018c46824d">add_constant</a> (const std::string &amp;name, const std::array&lt; size_t, 3 &gt; &amp;shape_c_h_w, weight_initializer weight_initializer_fn)</td></tr>
<tr class="separator:a4f0880d0964b3c08382d7c018c46824d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a575b67647ae4cbf2be46a01438b05c8b"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a575b67647ae4cbf2be46a01438b05c8b">add_reshape</a> (const std::string &amp;name, const std::string &amp;input, const std::array&lt; size_t, 4 &gt; &amp;seq_c_h_w)</td></tr>
<tr class="separator:a575b67647ae4cbf2be46a01438b05c8b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a722e25fe02cf66dcea3694b68df5bd46"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a722e25fe02cf66dcea3694b68df5bd46">add_permute</a> (const std::string &amp;name, const std::string &amp;input, const std::array&lt; size_t, 4 &gt; &amp;axis_permutation)</td></tr>
<tr class="separator:a722e25fe02cf66dcea3694b68df5bd46"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac18acd609ede2684ef4bd9a3d0af2e8c"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#ac18acd609ede2684ef4bd9a3d0af2e8c">add_channel_slice</a> (const std::string &amp;name, const std::string &amp;input, int start_index, int end_index, size_t stride)</td></tr>
<tr class="separator:ac18acd609ede2684ef4bd9a3d0af2e8c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab1990723baf0aeabc62ab8eb3616bfab"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#ab1990723baf0aeabc62ab8eb3616bfab">add_lstm</a> (const std::string &amp;name, const std::string &amp;input, const std::string &amp;hidden_input, const std::string &amp;cell_input, const std::string &amp;hidden_output, const std::string &amp;cell_output, size_t input_vector_size, size_t output_vector_size, float cell_clip_threshold, const <a class="el" href="structturi_1_1neural__net_1_1lstm__weight__initializers.html">lstm_weight_initializers</a> &amp;initializers)</td></tr>
<tr class="separator:ab1990723baf0aeabc62ab8eb3616bfab"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aea11bb9b939367688ecab3b89179b085"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#aea11bb9b939367688ecab3b89179b085">add_preprocessing</a> (const std::string &amp;feature_name, const float image_scale)</td></tr>
<tr class="separator:aea11bb9b939367688ecab3b89179b085"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab6b5815df87565bf4b3db027b31b747a"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#ab6b5815df87565bf4b3db027b31b747a">add_transpose</a> (const std::string &amp;name, const std::string &amp;input, std::vector&lt; size_t &gt; axes)</td></tr>
<tr class="separator:ab6b5815df87565bf4b3db027b31b747a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1d9da6c992e804a616ca3e7bff28b7ec"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a1d9da6c992e804a616ca3e7bff28b7ec">add_split_nd</a> (const std::string &amp;name, const std::string &amp;input, size_t axis, size_t num_splits, const std::vector&lt; size_t &gt; &amp;split_sizes)</td></tr>
<tr class="separator:a1d9da6c992e804a616ca3e7bff28b7ec"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a94cc9640242e3aab8545944914d6bbfe"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a94cc9640242e3aab8545944914d6bbfe">add_concat_nd</a> (const std::string &amp;name, const std::vector&lt; std::string &gt; &amp;inputs, size_t axis)</td></tr>
<tr class="separator:a94cc9640242e3aab8545944914d6bbfe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0c1360b84ce5e832496a5976b3671b50"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a0c1360b84ce5e832496a5976b3671b50">add_reshape_static</a> (const std::string &amp;name, const std::string &amp;input, const std::vector&lt; size_t &gt; &amp;targetShape)</td></tr>
<tr class="separator:a0c1360b84ce5e832496a5976b3671b50"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a48083b44b03ec490fae83c2569f7d91b"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a48083b44b03ec490fae83c2569f7d91b">add_reshape_dynamic</a> (const std::string &amp;name, const std::vector&lt; std::string &gt; &amp;inputs)</td></tr>
<tr class="separator:a48083b44b03ec490fae83c2569f7d91b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7aab4a8536faa481486e78d9a2bc8908"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a7aab4a8536faa481486e78d9a2bc8908">add_expand_dims</a> (const std::string &amp;name, const std::string &amp;input, const std::vector&lt; size_t &gt; &amp;axes, const std::vector&lt; size_t &gt; &amp;inputVector, const std::vector&lt; size_t &gt; &amp;outputVector)</td></tr>
<tr class="separator:a7aab4a8536faa481486e78d9a2bc8908"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a67fe899071de5d3f4d0a89c868e28a58"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a67fe899071de5d3f4d0a89c868e28a58">add_squeeze</a> (const std::string &amp;name, const std::string &amp;input, const std::vector&lt; size_t &gt; &amp;axes, const std::vector&lt; size_t &gt; &amp;inputVector, const std::vector&lt; size_t &gt; &amp;outputVector)</td></tr>
<tr class="separator:a67fe899071de5d3f4d0a89c868e28a58"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a63e2e02f964c41354ac0df70daaa111e"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a63e2e02f964c41354ac0df70daaa111e">add_add_broadcastable</a> (const std::string &amp;name, const std::vector&lt; std::string &gt; &amp;inputs)</td></tr>
<tr class="separator:a63e2e02f964c41354ac0df70daaa111e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa525faf4ef2058a4f4a6d4ab9bbc6248"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#aa525faf4ef2058a4f4a6d4ab9bbc6248">add_gather</a> (const std::string &amp;name, const std::vector&lt; std::string &gt; &amp;inputs)</td></tr>
<tr class="separator:aa525faf4ef2058a4f4a6d4ab9bbc6248"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acadf5c475d1fb43f22960e471c60d8c0"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#acadf5c475d1fb43f22960e471c60d8c0">add_constant_nd</a> (const std::string &amp;name, const std::vector&lt; size_t &gt; &amp;shape, const weight_initializer &amp;data)</td></tr>
<tr class="separator:acadf5c475d1fb43f22960e471c60d8c0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aab9dfdacbdf756d3a00e23e03ab397f9"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#aab9dfdacbdf756d3a00e23e03ab397f9">add_get_shape</a> (const std::string &amp;name, const std::string &amp;input)</td></tr>
<tr class="separator:aab9dfdacbdf756d3a00e23e03ab397f9"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>Representation for a neural-network model (structure and parameters), optimized for convenient export to CoreML.</p>
<p>This class just wraps CoreML::Specification::NeuralNetwork, helping to insulate toolkits from protobuf code. </p>

<p class="definition">Definition at line <a class="el" href="model__spec_8hpp_source.html#l00040">40</a> of file <a class="el" href="model__spec_8hpp_source.html">model_spec.hpp</a>.</p>
</div><h2 class="groupheader">Member Enumeration Documentation</h2>
<a id="a972ab38f4986dabfac28beaee2ae01ce"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a972ab38f4986dabfac28beaee2ae01ce">&#9670;&nbsp;</a></span>padding_policy</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">enum <a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a972ab38f4986dabfac28beaee2ae01ce">turi::neural_net::model_spec::padding_policy</a></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">strong</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Parameter for the padding layer </p>

<p class="definition">Definition at line <a class="el" href="model__spec_8hpp_source.html#l00050">50</a> of file <a class="el" href="model__spec_8hpp_source.html">model_spec.hpp</a>.</p>

</div>
</div>
<a id="a0d1aa5b0fcc3c11248e0a2e33c49ff4f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0d1aa5b0fcc3c11248e0a2e33c49ff4f">&#9670;&nbsp;</a></span>padding_type</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">enum <a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a0d1aa5b0fcc3c11248e0a2e33c49ff4f">turi::neural_net::model_spec::padding_type</a></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">strong</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Parameter for convolution and pooling layers. </p>

<p class="definition">Definition at line <a class="el" href="model__spec_8hpp_source.html#l00044">44</a> of file <a class="el" href="model__spec_8hpp_source.html">model_spec.hpp</a>.</p>

</div>
</div>
<h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="af1ff523b7e54fe4869bc6cbee430afaa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af1ff523b7e54fe4869bc6cbee430afaa">&#9670;&nbsp;</a></span>model_spec() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">turi::neural_net::model_spec::model_spec </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Creates an empty <a class="el" href="classturi_1_1neural__net_1_1model__spec.html">model_spec</a> (with no layers). </p>

</div>
</div>
<a id="afe558dd5f6c1480738de3da6e82c0d11"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afe558dd5f6c1480738de3da6e82c0d11">&#9670;&nbsp;</a></span>model_spec() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">turi::neural_net::model_spec::model_spec </td>
          <td>(</td>
          <td class="paramtype">const CoreML::Specification::NeuralNetwork &amp;&#160;</td>
          <td class="paramname"><em>nn_model</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Initializes a <a class="el" href="classturi_1_1neural__net_1_1model__spec.html">model_spec</a> from a NeuralNetwork proto. </p>

</div>
</div>
<a id="a7b0e02b00b3e555b59928311a0318439"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7b0e02b00b3e555b59928311a0318439">&#9670;&nbsp;</a></span>model_spec() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">turi::neural_net::model_spec::model_spec </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>mlmodel_path</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Initializes a <a class="el" href="classturi_1_1neural__net_1_1model__spec.html">model_spec</a> from the top-level NeuralNetwork found inside a CoreML model specification on disk.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">mlmodel_path</td><td>Path to a CoreM::Specification::Model proto on disk. </td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">If</td><td>the indicated path could not be read or parsed. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a63e2e02f964c41354ac0df70daaa111e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a63e2e02f964c41354ac0df70daaa111e">&#9670;&nbsp;</a></span>add_add_broadcastable()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_add_broadcastable </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; std::string &gt; &amp;&#160;</td>
          <td class="paramname"><em>inputs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends an Add Broadcastable layer.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">inputs</td><td>The vector of names of the layer's inputs </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a1e1623161bae417d84204c4e9b965c3b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1e1623161bae417d84204c4e9b965c3b">&#9670;&nbsp;</a></span>add_addition()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_addition </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; std::string &gt; &amp;&#160;</td>
          <td class="paramname"><em>inputs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a layer that performs elementwise addition.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">inputs</td><td>The names of the layer's inputs </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a583420894fa2754f703fa1933ba88f11"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a583420894fa2754f703fa1933ba88f11">&#9670;&nbsp;</a></span>add_batchnorm()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_batchnorm </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>num_channels</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>epsilon</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a batch norm layer.</p>
<p>The beta and mean parameters are initialized to 0.f; the gamma and variance parameters are initialized to 1.f</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">input</td><td>The name of the layer's input </td></tr>
    <tr><td class="paramname">num_channels</td><td>The C dimension of the input and output </td></tr>
    <tr><td class="paramname">epsilon</td><td>Added to the variance for each input before normalizing </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a58b191a4c24d2c4efb49c48ac8eb0ea0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a58b191a4c24d2c4efb49c48ac8eb0ea0">&#9670;&nbsp;</a></span>add_channel_concat()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_channel_concat </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; std::string &gt; &amp;&#160;</td>
          <td class="paramname"><em>inputs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a layer that concatenates its inputs along the channel axis.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">inputs</td><td>The names of the layer's inputs </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ac18acd609ede2684ef4bd9a3d0af2e8c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac18acd609ede2684ef4bd9a3d0af2e8c">&#9670;&nbsp;</a></span>add_channel_slice()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_channel_slice </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>start_index</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>end_index</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>stride</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a layer that slices the input along the channel axis.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">input</td><td>The name of the layer's input </td></tr>
    <tr><td class="paramname">start_index</td><td>The first channel to include </td></tr>
    <tr><td class="paramname">end_index</td><td>The first channel to stop including. If negative, then the number of channels is added first (so -1 becomes n - 1). </td></tr>
    <tr><td class="paramname">stride</td><td>The interval between channels to include </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a94cc9640242e3aab8545944914d6bbfe"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a94cc9640242e3aab8545944914d6bbfe">&#9670;&nbsp;</a></span>add_concat_nd()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_concat_nd </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; std::string &gt; &amp;&#160;</td>
          <td class="paramname"><em>inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>axis</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends an Concat layer.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">inputs</td><td>The vector of names of the layer's inputs </td></tr>
    <tr><td class="paramname">axis</td><td>The axis to concat the layer on </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a4f0880d0964b3c08382d7c018c46824d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4f0880d0964b3c08382d7c018c46824d">&#9670;&nbsp;</a></span>add_constant()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_constant </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::array&lt; size_t, 3 &gt; &amp;&#160;</td>
          <td class="paramname"><em>shape_c_h_w</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">weight_initializer&#160;</td>
          <td class="paramname"><em>weight_initializer_fn</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a layer with fixed values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">shape_c_h_w</td><td>The shape of the output </td></tr>
    <tr><td class="paramname">weight_initializer_fn</td><td>Callback used to initialize the weights </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="acadf5c475d1fb43f22960e471c60d8c0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acadf5c475d1fb43f22960e471c60d8c0">&#9670;&nbsp;</a></span>add_constant_nd()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_constant_nd </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; size_t &gt; &amp;&#160;</td>
          <td class="paramname"><em>shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const weight_initializer &amp;&#160;</td>
          <td class="paramname"><em>data</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a Constant ND layer.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">shape</td><td>The shape of the constant layer </td></tr>
    <tr><td class="paramname">data</td><td>The data being loaded in the constant layer </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a7ccd214f01f5f7d61ed0a22a090b8751"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7ccd214f01f5f7d61ed0a22a090b8751">&#9670;&nbsp;</a></span>add_convolution()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_convolution </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>num_output_channels</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>num_kernel_channels</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>kernel_height</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>kernel_width</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>stride_h</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>stride_w</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a0d1aa5b0fcc3c11248e0a2e33c49ff4f">padding_type</a>&#160;</td>
          <td class="paramname"><em>padding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">weight_initializer&#160;</td>
          <td class="paramname"><em>weight_initializer_fn</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">weight_initializer&#160;</td>
          <td class="paramname"><em>bias_initializer_fn</em> = <code>nullptr</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a convolution layer.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">input</td><td>The name of the layer's input </td></tr>
    <tr><td class="paramname">num_output_channels</td><td>The number of distinct filters in this layer </td></tr>
    <tr><td class="paramname">num_kernel_channels</td><td>The number of input features per "pixel" </td></tr>
    <tr><td class="paramname">kernel_size</td><td>The height and width of the kernel </td></tr>
    <tr><td class="paramname">weight_initializer_fn</td><td>Callback used to initialize the conv weights </td></tr>
    <tr><td class="paramname">bias_initializer_fn</td><td>Callback used to initialize the conv bias. If nullptr, then no bias vector is set. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a87f4589de4b9fa9ae4733a6229dd6c0e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a87f4589de4b9fa9ae4733a6229dd6c0e">&#9670;&nbsp;</a></span>add_exp()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_exp </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a layer that applies the unary function f(x) = e^x to its input.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">input</td><td>The name of the layer's input </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a7aab4a8536faa481486e78d9a2bc8908"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7aab4a8536faa481486e78d9a2bc8908">&#9670;&nbsp;</a></span>add_expand_dims()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_expand_dims </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; size_t &gt; &amp;&#160;</td>
          <td class="paramname"><em>axes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; size_t &gt; &amp;&#160;</td>
          <td class="paramname"><em>inputVector</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; size_t &gt; &amp;&#160;</td>
          <td class="paramname"><em>outputVector</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends an Expand Dims layer.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">input</td><td>The vector of names of the layer's input </td></tr>
    <tr><td class="paramname">axes</td><td>The axes to expand the layer on </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a4a12f8427abded091d6b9bc25758e217"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4a12f8427abded091d6b9bc25758e217">&#9670;&nbsp;</a></span>add_flatten()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_flatten </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a layer that performs flatten normalization (along channel axis).</p>
<p>currently only supports channel first flattening, which means if the input order is <code>[C, H, W]</code>, then output array will be <code>[C * H * W, 1, 1]</code>, still <code>C-major</code> orderring. No underlying array storage will be changed.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">input</td><td>The name of the layer's input </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="aa525faf4ef2058a4f4a6d4ab9bbc6248"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa525faf4ef2058a4f4a6d4ab9bbc6248">&#9670;&nbsp;</a></span>add_gather()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_gather </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; std::string &gt; &amp;&#160;</td>
          <td class="paramname"><em>inputs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a Gather layer.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">inputs</td><td>The vector of names of the layer's inputs </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="aab9dfdacbdf756d3a00e23e03ab397f9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aab9dfdacbdf756d3a00e23e03ab397f9">&#9670;&nbsp;</a></span>add_get_shape()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_get_shape </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a Get Shape layer.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">input</td><td>The vector of names of the layer's input </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a5265c68c0395de316c21f0c12ce699e3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5265c68c0395de316c21f0c12ce699e3">&#9670;&nbsp;</a></span>add_inner_product()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_inner_product </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>num_output_channels</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>num_input_channels</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">weight_initializer&#160;</td>
          <td class="paramname"><em>weight_initializer_fn</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">weight_initializer&#160;</td>
          <td class="paramname"><em>bias_initializer_fn</em> = <code>nullptr</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends an inner-product (dense, fully connected) layer.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">input</td><td>The name of the layer's input </td></tr>
    <tr><td class="paramname">num_output_channels</td><td>Size of the output vector </td></tr>
    <tr><td class="paramname">num_input_channels</td><td>Size of the input vector </td></tr>
    <tr><td class="paramname">weight_initializer_fn</td><td>Callback used to initialize the weights </td></tr>
    <tr><td class="paramname">bias_initializer_fn</td><td>Callback used to initialize the bias. If nullptr, then no bias vector is set. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ab27561c305aa88745d19e5ea44294d52"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab27561c305aa88745d19e5ea44294d52">&#9670;&nbsp;</a></span>add_instancenorm()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_instancenorm </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>num_channels</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>epsilon</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends an instance norm layer.</p>
<p>The beta is initialized to 0.f; the gamma is initialized to 1.f</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">input</td><td>The name of the layer's input </td></tr>
    <tr><td class="paramname">num_channels</td><td>The C dimension of the input and output </td></tr>
    <tr><td class="paramname">epsilon</td><td>Added to the variance for each input before normalizing </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="acb6626db8f0340e548cff0bd05ac0ad4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acb6626db8f0340e548cff0bd05ac0ad4">&#9670;&nbsp;</a></span>add_leakyrelu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_leakyrelu </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>alpha</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a leaky ReLU activation layer.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">input</td><td>The name of the layer's input </td></tr>
    <tr><td class="paramname">alpha</td><td>Multiplied to negative inputs </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ab1990723baf0aeabc62ab8eb3616bfab"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab1990723baf0aeabc62ab8eb3616bfab">&#9670;&nbsp;</a></span>add_lstm()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_lstm </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>hidden_input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>cell_input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>hidden_output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>cell_output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>input_vector_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>output_vector_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>cell_clip_threshold</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structturi_1_1neural__net_1_1lstm__weight__initializers.html">lstm_weight_initializers</a> &amp;&#160;</td>
          <td class="paramname"><em>initializers</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends an LSTM layer.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">input</td><td>The name of the layer's input </td></tr>
    <tr><td class="paramname">hidden_input</td><td>The name of the initial hidden state </td></tr>
    <tr><td class="paramname">cell_input</td><td>The name of the initial cell state </td></tr>
    <tr><td class="paramname">hidden_output</td><td>The name of the resulting hidden state </td></tr>
    <tr><td class="paramname">cell_output</td><td>The name of the resulting cell state </td></tr>
    <tr><td class="paramname">input_vector_size</td><td>The size of the input vector </td></tr>
    <tr><td class="paramname">output_vector_size</td><td>The size of the output vector (hidden state and cell state) </td></tr>
    <tr><td class="paramname">cell_clip_threshold</td><td>Maximum magnitude of cell state values </td></tr>
    <tr><td class="paramname">initializers</td><td>LSTM weights </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a3a17edc293d3f7bf22cc32ac23183ade"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3a17edc293d3f7bf22cc32ac23183ade">&#9670;&nbsp;</a></span>add_multiplication()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_multiplication </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; std::string &gt; &amp;&#160;</td>
          <td class="paramname"><em>inputs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a layer that performs elementwise multiplication.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">inputs</td><td>The names of the layer's inputs </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="aea19bc2e165a8934924604187c3e7945"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aea19bc2e165a8934924604187c3e7945">&#9670;&nbsp;</a></span>add_padding()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_padding </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>padding_top</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>padding_bottom</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>padding_left</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>padding_right</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a972ab38f4986dabfac28beaee2ae01ce">padding_policy</a>&#160;</td>
          <td class="paramname"><em>policy</em> = <code>padding_policy::REFLECTIVE</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a padding layer.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">input</td><td>The name of the layer's input </td></tr>
    <tr><td class="paramname">padding_top</td><td>The padding on the top </td></tr>
    <tr><td class="paramname">padding_bottom</td><td>The padding on the bottom </td></tr>
    <tr><td class="paramname">padding_left</td><td>The padding to the left </td></tr>
    <tr><td class="paramname">padding_right</td><td>The padding to the right </td></tr>
    <tr><td class="paramname">policy</td><td>The padding policy of zero, reflective, or replication </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a722e25fe02cf66dcea3694b68df5bd46"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a722e25fe02cf66dcea3694b68df5bd46">&#9670;&nbsp;</a></span>add_permute()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_permute </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::array&lt; size_t, 4 &gt; &amp;&#160;</td>
          <td class="paramname"><em>axis_permutation</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a layer that transposes the dimensions of its input</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">input</td><td>The name of the layer's input </td></tr>
    <tr><td class="paramname">axis_permutation</td><td>A permutation of [0, 1, 2, 3], describing how to rearrange the [Seq, C, H, W] input. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="aafcbd879d251f3e3ffff3432b25b5df4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aafcbd879d251f3e3ffff3432b25b5df4">&#9670;&nbsp;</a></span>add_pooling()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_pooling </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>kernel_height</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>kernel_width</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>stride_h</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>stride_w</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html#a0d1aa5b0fcc3c11248e0a2e33c49ff4f">padding_type</a>&#160;</td>
          <td class="paramname"><em>padding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>use_poolexcludepadding</em> = <code>false</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a pooling layer. By default, it's a max pooling layer. And it can only be max pooling TODO: be able to set other pooling types</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">use_poolexcludepadding</td><td>padded values are excluded from the count (denominator) when computing average pooling. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="aea11bb9b939367688ecab3b89179b085"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aea11bb9b939367688ecab3b89179b085">&#9670;&nbsp;</a></span>add_preprocessing()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_preprocessing </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>feature_name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const float&#160;</td>
          <td class="paramname"><em>image_scale</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a preprocessing layer Now only support image scaling preprocessing though. </p>

</div>
</div>
<a id="afa970eb6f824e6cf77d4de223594bd3b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afa970eb6f824e6cf77d4de223594bd3b">&#9670;&nbsp;</a></span>add_relu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_relu </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a ReLU activation layer.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">input</td><td>The name of the layer's input </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a575b67647ae4cbf2be46a01438b05c8b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a575b67647ae4cbf2be46a01438b05c8b">&#9670;&nbsp;</a></span>add_reshape()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_reshape </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::array&lt; size_t, 4 &gt; &amp;&#160;</td>
          <td class="paramname"><em>seq_c_h_w</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a layer that reshapes its input.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">input</td><td>The name of the layer's input </td></tr>
    <tr><td class="paramname">shape_c_h_w</td><td>The shape of the output </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a48083b44b03ec490fae83c2569f7d91b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a48083b44b03ec490fae83c2569f7d91b">&#9670;&nbsp;</a></span>add_reshape_dynamic()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_reshape_dynamic </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; std::string &gt; &amp;&#160;</td>
          <td class="paramname"><em>inputs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a Reshape Dynamic layer.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">inputs</td><td>The vector of names of the layer's inputs </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a0c1360b84ce5e832496a5976b3671b50"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0c1360b84ce5e832496a5976b3671b50">&#9670;&nbsp;</a></span>add_reshape_static()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_reshape_static </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; size_t &gt; &amp;&#160;</td>
          <td class="paramname"><em>targetShape</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a Reshape Static layer.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">input</td><td>The vector of names of the layer's input </td></tr>
    <tr><td class="paramname">targetShape</td><td>The target shape </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a6c69a0731e05e63c9a8f7545381ac730"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6c69a0731e05e63c9a8f7545381ac730">&#9670;&nbsp;</a></span>add_scale()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_scale </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; size_t &gt; &amp;&#160;</td>
          <td class="paramname"><em>shape_c_h_w</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">weight_initializer&#160;</td>
          <td class="paramname"><em>scale_initializer_fn</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a layer that performs elementwise multiplication between its input and some fixed weights.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">input</td><td>The name of the layer's input </td></tr>
    <tr><td class="paramname">shape_c_h_w</td><td>The shape of the input and output </td></tr>
    <tr><td class="paramname">weight_initializer_fn</td><td>Callback used to initialize the weights </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a18df584c6e1eef1cf34fbcb043e935dd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a18df584c6e1eef1cf34fbcb043e935dd">&#9670;&nbsp;</a></span>add_sigmoid()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_sigmoid </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a sigmoid activation layer.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">input</td><td>The name of the layer's input </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a903131139a2277c91efae7e68916f13a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a903131139a2277c91efae7e68916f13a">&#9670;&nbsp;</a></span>add_softmax()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_softmax </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a layer that performs softmax normalization (along channel axis).</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">input</td><td>The name of the layer's input </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a1d9da6c992e804a616ca3e7bff28b7ec"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1d9da6c992e804a616ca3e7bff28b7ec">&#9670;&nbsp;</a></span>add_split_nd()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_split_nd </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>axis</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>num_splits</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; size_t &gt; &amp;&#160;</td>
          <td class="paramname"><em>split_sizes</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends an Split layer.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">input</td><td>The name of the layer's input </td></tr>
    <tr><td class="paramname">axis</td><td>The axis to split the layer on </td></tr>
    <tr><td class="paramname">num_splits</td><td>The number of splits to perform </td></tr>
    <tr><td class="paramname">split_sizes</td><td>The size of each split </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a67fe899071de5d3f4d0a89c868e28a58"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a67fe899071de5d3f4d0a89c868e28a58">&#9670;&nbsp;</a></span>add_squeeze()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_squeeze </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; size_t &gt; &amp;&#160;</td>
          <td class="paramname"><em>axes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; size_t &gt; &amp;&#160;</td>
          <td class="paramname"><em>inputVector</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; size_t &gt; &amp;&#160;</td>
          <td class="paramname"><em>outputVector</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends a Squeeze layer.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">input</td><td>The vector of names of the layer's input </td></tr>
    <tr><td class="paramname">axes</td><td>The axes to squeeze the layer on </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ab6b5815df87565bf4b3db027b31b747a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab6b5815df87565bf4b3db027b31b747a">&#9670;&nbsp;</a></span>add_transpose()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_transpose </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::vector&lt; size_t &gt;&#160;</td>
          <td class="paramname"><em>axes</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends an Transpose layer.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">input</td><td>The name of the layer's input </td></tr>
    <tr><td class="paramname">axes</td><td>The ordering of the axes to transpose for instance {0, 2, 1, 3} would flip the channel and height axes </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a54185bc37553c8ea489b2f062e5d58d6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a54185bc37553c8ea489b2f062e5d58d6">&#9670;&nbsp;</a></span>add_upsampling()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::add_upsampling </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>scaling_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>scaling_y</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Appends an upsampling layer.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the layer and its output </td></tr>
    <tr><td class="paramname">input</td><td>The name of the layer's input </td></tr>
    <tr><td class="paramname">scaling_x</td><td>The upsample scale on the x axis </td></tr>
    <tr><td class="paramname">scaling_y</td><td>The upsample scale on the y axis </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a773b3150e362e3e5fb094e75b92baf36"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a773b3150e362e3e5fb094e75b92baf36">&#9670;&nbsp;</a></span>export_params_view()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">float_array_map turi::neural_net::model_spec::export_params_view </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Creates a shared_float_array view (weak reference) into the parameters of the model, indexed by layer name.</p>
<dl class="section return"><dt>Returns</dt><dd>A dictionary whose keys are of the form "$layername_$paramname". The layer names are taken from the name field of each NeuralNetworkLayer containing a supported layer. The supported layers are ConvolutionLayerParams (with params "weight" (in NCHW order) and "bias") and BatchnormLayerParams (with params "gamma", "beta", "running_mean", and "running_var"). </dd></dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">If</td><td>a NeuralNetworkLayer in the specification seems malformed (e.g. WeightParams with size inconsistent with declared layer shape).</td></tr>
  </table>
  </dd>
</dl>
<p>To avoid copying data, the data backing the shared_float_array instances in the return value will only remain valid for the lifetime of this instance! </p>

</div>
</div>
<a id="a4d8bdc11e8d0b74a416a9ccfba8cb4c8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4d8bdc11e8d0b74a416a9ccfba8cb4c8">&#9670;&nbsp;</a></span>get_coreml_spec()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">const CoreML::Specification::NeuralNetwork&amp; turi::neural_net::model_spec::get_coreml_spec </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Exposes the underlying CoreML proto. </p>

<p class="definition">Definition at line <a class="el" href="model__spec_8hpp_source.html#l00085">85</a> of file <a class="el" href="model__spec_8hpp_source.html">model_spec.hpp</a>.</p>

</div>
</div>
<a id="accf5b8ba3d48fdaf91f66a680260a216"></a>
<h2 class="memtitle"><span class="permalink"><a href="#accf5b8ba3d48fdaf91f66a680260a216">&#9670;&nbsp;</a></span>has_layer_output()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">bool turi::neural_net::model_spec::has_layer_output </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>layer_name</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Determines whether the neural network contains a layer with the given output name.</p>
<p>In general, it is only safe to add a new layer that takes a named input if this method returns true for that name. </p>

</div>
</div>
<a id="abd51b4228a76c35335450b7066f8f86c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abd51b4228a76c35335450b7066f8f86c">&#9670;&nbsp;</a></span>move_coreml_spec()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::unique_ptr&lt;CoreML::Specification::NeuralNetwork&gt; turi::neural_net::model_spec::move_coreml_spec </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> &amp;&amp;</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Transfer ownership of the underlying CoreML proto, invalidating the current instance (leaving it in a "moved-from" state).</p>
<p>(Note that this method may only be invoked from a <a class="el" href="classturi_1_1neural__net_1_1model__spec.html">model_spec</a>&amp;&amp;) </p>

</div>
</div>
<a id="aec2f3705367eac080429f63f2623166c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aec2f3705367eac080429f63f2623166c">&#9670;&nbsp;</a></span>update_params()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void turi::neural_net::model_spec::update_params </td>
          <td>(</td>
          <td class="paramtype">const float_array_map &amp;&#160;</td>
          <td class="paramname"><em>weights</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Overwrites existing WeightParams values using the provided float_array values.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">weights</td><td>A dictionary whose keys follow the same naming scheme used by <code>export_params_view</code>. </td></tr>
  </table>
  </dd>
</dl>
<dl class="exception"><dt>Exceptions</dt><dd>
  <table class="exception">
    <tr><td class="paramname">If</td><td>a float_array's shape does not match the corresponding NeuralNetworkLayer. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>ml/neural_net/<a class="el" href="model__spec_8hpp_source.html">model_spec.hpp</a></li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="namespaceturi.html">turi</a></li><li class="navelem"><b>neural_net</b></li><li class="navelem"><a class="el" href="classturi_1_1neural__net_1_1model__spec.html">model_spec</a></li>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.13 </li>
  </ul>
</div>
</body>
</html>
